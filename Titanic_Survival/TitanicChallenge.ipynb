{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TitanicChallenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXQP_rpWEwx9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import rcParams\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwFWq3bHGu1"
      },
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPFArMqFGqpb"
      },
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "df = pd.concat([train, test], axis=0, sort=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ5Z4iNIPgw"
      },
      "source": [
        "Checking the ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6c4MjpsISNv",
        "outputId": "d5b55fc7-9064-4b74-c513-9eeea3443848"
      },
      "source": [
        "df['Survived'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    549\n",
              "1.0    342\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3FdTQcAIsVZ"
      },
      "source": [
        "replaced some of the uncommon titles with more common ones for the sake of simplicity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAMISbL1Itmi",
        "outputId": "3dce563e-16f4-4413-e6c8-25adfecb975f"
      },
      "source": [
        "df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
        "\n",
        "# replacing some titles with more common ones\n",
        "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n",
        "           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n",
        "           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
        "df.replace({'Title': mapping}, inplace=True)\n",
        "\n",
        "df['Title'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mr        767\n",
              "Miss      264\n",
              "Mrs       201\n",
              "Master     61\n",
              "Dr          8\n",
              "Rev         8\n",
              "Name: Title, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0uhI2usI10o"
      },
      "source": [
        "Everyone can be grouped into 6 titles and using the titles we created, we can fill in missing ages using the median of all the other individuals with the same title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "1P6n8a8sIy2N",
        "outputId": "2c055b93-0de6-4339-f142-1af9cf02ef08"
      },
      "source": [
        "#input missing age values using median of title groups\n",
        "\n",
        "title_ages = dict(df.groupby('Title')['Age'].median())\n",
        "\n",
        "df['age_med'] = df['Title'].apply(lambda x: title_ages[x])\n",
        "\n",
        "# replace all missing ages with the value in this column\n",
        "df['Age'].fillna(df['age_med'], inplace=True, )\n",
        "del df['age_med']\n",
        "\n",
        "# viz of survival rates of titles\n",
        "\n",
        "sns.countplot(x='Title', data=df, hue='Survived')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HabuWBG8Jrlw"
      },
      "source": [
        "Next, I do something similar as I did with missing age values, but this time with missing fare values. I used the median fare value for each passenger class as the value for corresponding missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHRgNUaJgrm"
      },
      "source": [
        "# impute missing Fare values using median of Pclass groups\n",
        "class_fares = dict(df.groupby('Pclass')['Fare'].median())\n",
        "\n",
        "# create a column of the average fares\n",
        "df['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x])\n",
        "\n",
        "# replace all missing fares with the value in this column\n",
        "df['Fare'].fillna(df['fare_med'], inplace=True, )\n",
        "del df['fare_med']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Ot8yXwKuHM"
      },
      "source": [
        "There are only 2 missing values in ‘Embarked’ so just I use the method backfill to get rid of the null values. I also create a new variable in the dataset called family size, calculated using the two variables of Parch and SibSp and adding them together.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWjFKYlEKvN4"
      },
      "source": [
        "\n",
        "df['Embarked'].fillna(method='backfill', inplace=True)\n",
        "\n",
        "df['Family_Size'] = df['Parch'] + df['SibSp']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo-9W2efK7vo"
      },
      "source": [
        "Spliting up data again for training & testing for making up the neural network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck-qNvxNLa80"
      },
      "source": [
        "train = df[pd.notnull(df['Survived'])]\n",
        "test  = df[pd.isnull(df['Survived'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYQdIlbqLzd8"
      },
      "source": [
        "Importing some more libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q36CjOLaL2YD"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "from numpy.random import seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8_qTKtpMBPC"
      },
      "source": [
        "Droping some of the variables that wont be used.\n",
        "\n",
        "Also scaling some continous variables to make it simpler for neural network to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dBSv4uNWMSDS",
        "outputId": "44d544b4-abc3-429d-ebf9-0f3b33e3842c"
      },
      "source": [
        "df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n",
        "\n",
        "continuous = ['Age','Fare','Parch','Pclass','SibSp','Family_Size']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for var in continuous:\n",
        "     df[var] = df[var].astype('float64')\n",
        "     df[var] = scaler.fit_transform(df[var].values.reshape(-1, 1))\n",
        "   \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Title</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.574635</td>\n",
              "      <td>S</td>\n",
              "      <td>-0.503176</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>0.841916</td>\n",
              "      <td>male</td>\n",
              "      <td>0.481288</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>0.073352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.641140</td>\n",
              "      <td>C</td>\n",
              "      <td>0.734809</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-1.546098</td>\n",
              "      <td>female</td>\n",
              "      <td>0.481288</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>0.073352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.270692</td>\n",
              "      <td>S</td>\n",
              "      <td>-0.490126</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>0.841916</td>\n",
              "      <td>female</td>\n",
              "      <td>-0.479087</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Miss</td>\n",
              "      <td>-0.558346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.413182</td>\n",
              "      <td>S</td>\n",
              "      <td>0.383263</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>-1.546098</td>\n",
              "      <td>female</td>\n",
              "      <td>0.481288</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Mrs</td>\n",
              "      <td>0.073352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.413182</td>\n",
              "      <td>S</td>\n",
              "      <td>-0.487709</td>\n",
              "      <td>-0.445</td>\n",
              "      <td>0.841916</td>\n",
              "      <td>male</td>\n",
              "      <td>-0.479087</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Mr</td>\n",
              "      <td>-0.558346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Age Embarked      Fare  Parch  ...     SibSp Survived  Title  Family_Size\n",
              "0 -0.574635        S -0.503176 -0.445  ...  0.481288      0.0     Mr     0.073352\n",
              "1  0.641140        C  0.734809 -0.445  ...  0.481288      1.0    Mrs     0.073352\n",
              "2 -0.270692        S -0.490126 -0.445  ... -0.479087      1.0   Miss    -0.558346\n",
              "3  0.413182        S  0.383263 -0.445  ...  0.481288      1.0    Mrs     0.073352\n",
              "4  0.413182        S -0.487709 -0.445  ... -0.479087      0.0     Mr    -0.558346\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xcUJgLmOOQm"
      },
      "source": [
        "Splitting the data into training and testing data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAfrFyKMOVaA"
      },
      "source": [
        "X_train= df[pd.notnull(df['Survived'])].drop(['Survived'],axis=1)\n",
        "y_train= df[pd.notnull(df['Survived'])]['Survived']\n",
        "X_test = df[pd.isnull(df['Survived'])].drop(['Survived'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKxbAyA3PV9F"
      },
      "source": [
        "Converting all the columns into feature columns for processing and creating the model.\n",
        "\n",
        "We create an input function that would feed dataframe into out classified model.\n",
        "\n",
        "Tf.estimator.inputs provide a very simple way for doing this \n",
        "\n",
        " It just requires specific features, labels, and batch size. It also has a special argument called shuffle, which allows the model to read the records in a random order, thereby improving model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nabkx_buSPQQ"
      },
      "source": [
        "I also defined our linear classifier. This linear classifier will train a linear model to classify things into one of the two possible classes - i.e. 0 for survival and 0 for not surviving. tf.estimator.LinearClassifier allows this to happen with just a single line of code. As a part of arguments, we have to specify our feature columns, which we created earlier. I also separate our training set into a training set and validation set to validate the model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRAC_Xk8PzZ0",
        "outputId": "31148cae-1d29-44b2-9938-2b8e32686cd4"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "Sex = tf.feature_column.categorical_column_with_vocabulary_list(\"Sex\", [\"female\", \"male\"])\n",
        "Embarked = tf.feature_column.categorical_column_with_vocabulary_list(\"Embarked\", [\"S\", \"C\", \"Q\"])\n",
        "Title = tf.feature_column.categorical_column_with_vocabulary_list(\"Title\", ['Mr', 'Mrs', 'Miss', 'Master', 'Rev', 'Dr'])\n",
        "Age = tf.feature_column.numeric_column(\"Age\")\n",
        "Fare = tf.feature_column.numeric_column(\"Fare\")\n",
        "Parch = tf.feature_column.numeric_column(\"Parch\")\n",
        "Pclass = tf.feature_column.numeric_column(\"Pclass\")\n",
        "SibSp = tf.feature_column.numeric_column(\"SibSp\")\n",
        "Family_Size = tf.feature_column.numeric_column(\"Family_Size\")\n",
        "\n",
        "feat_cols = [Sex, Embarked, Title, Age, Fare, Parch, Pclass, SibSp, Family_Size]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
        "\n",
        "input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,\n",
        "                                               y=y_train,\n",
        "                                               batch_size=100,\n",
        "                                               num_epochs=None,\n",
        "                                               shuffle=True)\n",
        "\n",
        "\n",
        "model = tf.estimator.LinearClassifier(feature_columns = feat_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8rkaq9q3\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8rkaq9q3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nARn-b1SQ3U"
      },
      "source": [
        "Next, I train my model using max 10000 steps to make sure it does not run forever. We can then use the input function to create a list of predictions that pulls from ‘predictions’ and adds the list of 1’s and 0’s we want into ‘final_preds’. Once we have that, we can print the classification report for our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6_c8RxUSX-R",
        "outputId": "4cc50df6-8fc4-4eea-a027-35f85a1de9d7"
      },
      "source": [
        "model.train(input_fn=input_func,max_steps=10000)\n",
        "\n",
        "pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_val,batch_size=len(X_val),shuffle=False)\n",
        "\n",
        "predictions = list(model.predict(input_fn=pred_fn))\n",
        "final_preds = []\n",
        "for pred in predictions:\n",
        "    final_preds.append(pred['class_ids'][0])\n",
        "    \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val,final_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:134: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8rkaq9q3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.6931472, step = 0\n",
            "INFO:tensorflow:global_step/sec: 138.121\n",
            "INFO:tensorflow:loss = 0.40652457, step = 100 (0.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.893\n",
            "INFO:tensorflow:loss = 0.4061792, step = 200 (0.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.306\n",
            "INFO:tensorflow:loss = 0.34654462, step = 300 (0.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.299\n",
            "INFO:tensorflow:loss = 0.4288449, step = 400 (0.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 156.02\n",
            "INFO:tensorflow:loss = 0.42812598, step = 500 (0.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.542\n",
            "INFO:tensorflow:loss = 0.2943638, step = 600 (0.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.823\n",
            "INFO:tensorflow:loss = 0.31828204, step = 700 (0.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.91\n",
            "INFO:tensorflow:loss = 0.36685017, step = 800 (0.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.519\n",
            "INFO:tensorflow:loss = 0.42884701, step = 900 (0.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 152.839\n",
            "INFO:tensorflow:loss = 0.43921113, step = 1000 (0.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.239\n",
            "INFO:tensorflow:loss = 0.33970234, step = 1100 (0.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.91\n",
            "INFO:tensorflow:loss = 0.35773036, step = 1200 (0.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.815\n",
            "INFO:tensorflow:loss = 0.3914009, step = 1300 (0.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 163.364\n",
            "INFO:tensorflow:loss = 0.4124417, step = 1400 (0.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 163.293\n",
            "INFO:tensorflow:loss = 0.33424354, step = 1500 (0.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.976\n",
            "INFO:tensorflow:loss = 0.28388852, step = 1600 (0.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.618\n",
            "INFO:tensorflow:loss = 0.48204666, step = 1700 (0.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.052\n",
            "INFO:tensorflow:loss = 0.4751306, step = 1800 (0.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 150.668\n",
            "INFO:tensorflow:loss = 0.40201122, step = 1900 (0.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.124\n",
            "INFO:tensorflow:loss = 0.31144983, step = 2000 (0.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.069\n",
            "INFO:tensorflow:loss = 0.32031357, step = 2100 (0.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.824\n",
            "INFO:tensorflow:loss = 0.48525986, step = 2200 (0.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 163.433\n",
            "INFO:tensorflow:loss = 0.4125565, step = 2300 (0.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.805\n",
            "INFO:tensorflow:loss = 0.37494874, step = 2400 (0.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 164.544\n",
            "INFO:tensorflow:loss = 0.41883972, step = 2500 (0.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.667\n",
            "INFO:tensorflow:loss = 0.32292116, step = 2600 (0.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 164.698\n",
            "INFO:tensorflow:loss = 0.42839277, step = 2700 (0.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 156.466\n",
            "INFO:tensorflow:loss = 0.36473522, step = 2800 (0.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.148\n",
            "INFO:tensorflow:loss = 0.39676476, step = 2900 (0.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.903\n",
            "INFO:tensorflow:loss = 0.5334844, step = 3000 (0.625 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.738\n",
            "INFO:tensorflow:loss = 0.39738584, step = 3100 (0.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.054\n",
            "INFO:tensorflow:loss = 0.41045025, step = 3200 (0.643 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3201 vs previous value: 3201. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 158.943\n",
            "INFO:tensorflow:loss = 0.35969532, step = 3300 (0.625 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.413\n",
            "INFO:tensorflow:loss = 0.44743606, step = 3400 (0.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.955\n",
            "INFO:tensorflow:loss = 0.35950404, step = 3500 (0.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.847\n",
            "INFO:tensorflow:loss = 0.34903318, step = 3600 (0.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.755\n",
            "INFO:tensorflow:loss = 0.36983708, step = 3700 (0.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 164.103\n",
            "INFO:tensorflow:loss = 0.4994681, step = 3800 (0.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.124\n",
            "INFO:tensorflow:loss = 0.33142605, step = 3900 (0.625 sec)\n",
            "INFO:tensorflow:global_step/sec: 163.087\n",
            "INFO:tensorflow:loss = 0.3975772, step = 4000 (0.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.177\n",
            "INFO:tensorflow:loss = 0.47364628, step = 4100 (0.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.236\n",
            "INFO:tensorflow:loss = 0.3766685, step = 4200 (0.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.229\n",
            "INFO:tensorflow:loss = 0.34554702, step = 4300 (0.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.872\n",
            "INFO:tensorflow:loss = 0.39433408, step = 4400 (0.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.726\n",
            "INFO:tensorflow:loss = 0.31726044, step = 4500 (0.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.776\n",
            "INFO:tensorflow:loss = 0.39844027, step = 4600 (0.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.174\n",
            "INFO:tensorflow:loss = 0.383343, step = 4700 (0.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.596\n",
            "INFO:tensorflow:loss = 0.32625863, step = 4800 (0.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 148.124\n",
            "INFO:tensorflow:loss = 0.4079306, step = 4900 (0.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 150.69\n",
            "INFO:tensorflow:loss = 0.30859998, step = 5000 (0.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.595\n",
            "INFO:tensorflow:loss = 0.4580575, step = 5100 (0.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.177\n",
            "INFO:tensorflow:loss = 0.31837505, step = 5200 (0.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 164.437\n",
            "INFO:tensorflow:loss = 0.35638493, step = 5300 (0.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.3\n",
            "INFO:tensorflow:loss = 0.40938434, step = 5400 (0.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.414\n",
            "INFO:tensorflow:loss = 0.37965843, step = 5500 (0.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 164.812\n",
            "INFO:tensorflow:loss = 0.30522284, step = 5600 (0.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.505\n",
            "INFO:tensorflow:loss = 0.36030933, step = 5700 (0.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.766\n",
            "INFO:tensorflow:loss = 0.31798396, step = 5800 (0.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.158\n",
            "INFO:tensorflow:loss = 0.29062077, step = 5900 (0.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.005\n",
            "INFO:tensorflow:loss = 0.3256015, step = 6000 (0.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.578\n",
            "INFO:tensorflow:loss = 0.387517, step = 6100 (0.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.992\n",
            "INFO:tensorflow:loss = 0.36823142, step = 6200 (0.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.958\n",
            "INFO:tensorflow:loss = 0.517492, step = 6300 (0.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.892\n",
            "INFO:tensorflow:loss = 0.3555359, step = 6400 (0.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.459\n",
            "INFO:tensorflow:loss = 0.38778096, step = 6500 (0.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.128\n",
            "INFO:tensorflow:loss = 0.38554123, step = 6600 (0.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.485\n",
            "INFO:tensorflow:loss = 0.36818755, step = 6700 (0.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 163.302\n",
            "INFO:tensorflow:loss = 0.35388383, step = 6800 (0.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.463\n",
            "INFO:tensorflow:loss = 0.39306912, step = 6900 (0.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.036\n",
            "INFO:tensorflow:loss = 0.3189517, step = 7000 (0.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.478\n",
            "INFO:tensorflow:loss = 0.35853648, step = 7100 (0.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.307\n",
            "INFO:tensorflow:loss = 0.43419376, step = 7200 (0.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 156.957\n",
            "INFO:tensorflow:loss = 0.33754212, step = 7300 (0.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.967\n",
            "INFO:tensorflow:loss = 0.45383847, step = 7400 (0.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.974\n",
            "INFO:tensorflow:loss = 0.41545323, step = 7500 (0.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 160.227\n",
            "INFO:tensorflow:loss = 0.4002485, step = 7600 (0.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 161.808\n",
            "INFO:tensorflow:loss = 0.29782838, step = 7700 (0.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 157.737\n",
            "INFO:tensorflow:loss = 0.43616626, step = 7800 (0.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 148.172\n",
            "INFO:tensorflow:loss = 0.2777749, step = 7900 (0.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 154.218\n",
            "INFO:tensorflow:loss = 0.3530464, step = 8000 (0.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.19\n",
            "INFO:tensorflow:loss = 0.38029927, step = 8100 (0.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 155.759\n",
            "INFO:tensorflow:loss = 0.44379792, step = 8200 (0.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 155.131\n",
            "INFO:tensorflow:loss = 0.43647233, step = 8300 (0.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 155.135\n",
            "INFO:tensorflow:loss = 0.35782325, step = 8400 (0.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 156.726\n",
            "INFO:tensorflow:loss = 0.3352889, step = 8500 (0.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 151.105\n",
            "INFO:tensorflow:loss = 0.3711079, step = 8600 (0.660 sec)\n",
            "INFO:tensorflow:global_step/sec: 152.833\n",
            "INFO:tensorflow:loss = 0.32437012, step = 8700 (0.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.258\n",
            "INFO:tensorflow:loss = 0.33630192, step = 8800 (0.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.319\n",
            "INFO:tensorflow:loss = 0.28143668, step = 8900 (0.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 159.35\n",
            "INFO:tensorflow:loss = 0.4459238, step = 9000 (0.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 162.783\n",
            "INFO:tensorflow:loss = 0.36134765, step = 9100 (0.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 158.847\n",
            "INFO:tensorflow:loss = 0.31015044, step = 9200 (0.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 155.879\n",
            "INFO:tensorflow:loss = 0.30702695, step = 9300 (0.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 154.167\n",
            "INFO:tensorflow:loss = 0.51321965, step = 9400 (0.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 151.265\n",
            "INFO:tensorflow:loss = 0.3159731, step = 9500 (0.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 151.835\n",
            "INFO:tensorflow:loss = 0.45082152, step = 9600 (0.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 152.403\n",
            "INFO:tensorflow:loss = 0.37713695, step = 9700 (0.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 153.942\n",
            "INFO:tensorflow:loss = 0.47588548, step = 9800 (0.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 155.578\n",
            "INFO:tensorflow:loss = 0.28152207, step = 9900 (0.643 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp8rkaq9q3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
            "INFO:tensorflow:Loss for final step: 0.31639645.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8rkaq9q3/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.86      0.84        91\n",
            "         1.0       0.73      0.69      0.71        52\n",
            "\n",
            "    accuracy                           0.80       143\n",
            "   macro avg       0.78      0.77      0.78       143\n",
            "weighted avg       0.80      0.80      0.80       143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}